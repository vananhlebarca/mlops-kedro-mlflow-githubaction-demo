# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/05_data/01_data_catalog.html
leads_dataset:
  type: pandas.CSVDataSet
  filepath: data/01_raw/leads_dataset.csv

leads_daily:
  type: pandas.ParquetDataSet
  filepath: data/01_raw/leads_daily.parquet
  load_args:
  save_args:
    compression: GZIP

leads_daily_predicted:
  type: pandas.CSVDataSet
  filepath: data/08_reporting/leads_daily_predicted.csv
  #versioned: true

leads_dataset_clean:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/leads_dataset_clean.csv

train_x:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/train_x.csv
  #versioned: true

train_x_clean:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/train_x_clean.csv
  #versioned: true

train_y:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/train_y.csv
  #versioned: true

test_x:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/test_x.csv
  #versioned: true

test_x_clean:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/test_x_clean.csv
  #versioned: true

test_y:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/test_y.csv
  #versioned: true

scaler:
  type: pickle.PickleDataSet
  filepath: data/06_models/scaler.pkl
  backend: pickle
  #versioned: true

rf_model:
  type: pickle.PickleDataSet
  filepath: data/06_models/rf_model.pkl
  backend: pickle
  #versioned: true

onehotencoder:
  type: pickle.PickleDataSet
  filepath: data/06_models/onhotencoder.pkl
  backend: pickle
  #versioned: true

mlflow_latest_run:
  type: kedro.extras.datasets.yaml.YAMLDataSet
  filepath: data/06_models/mlflow_latest_run.yaml
